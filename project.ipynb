{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7a403a-b500-4bee-bec9-625f3278d4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 17:11:06.052344: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-11 17:11:06.094403: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 17:11:06.094461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 17:11:06.095645: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 17:11:06.102337: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-11 17:11:06.102979: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 17:11:07.107285: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# You will probably need to install Tensorflow & Keras\n",
    "# Note: TensorFlow & Numpy often have version mismatches & \n",
    "#       you may need to roll back your Numpy version\n",
    "import sys\n",
    "#!{sys.executable} -m pip install scikit-image\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as scipy\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d6bd4a-9c14-40ff-a12d-6d650c34369c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image data/apple/.ipynb_checkpoints: [Errno 21] Is a directory: 'data/apple/.ipynb_checkpoints'\n",
      "Error loading image data/banana/.ipynb_checkpoints: [Errno 21] Is a directory: 'data/banana/.ipynb_checkpoints'\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(root_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_folder in os.listdir(root_folder):\n",
    "        class_folder_path = os.path.join(root_folder, class_folder)\n",
    "        if os.path.isdir(class_folder_path):\n",
    "            for image_name in os.listdir(class_folder_path):\n",
    "                image_path = os.path.join(class_folder_path, image_name)\n",
    "                try:\n",
    "                    img = mpimg.imread(image_path)\n",
    "                    #plt.imshow(img, cmap='gray')\n",
    "                    img_array = np.array(img)\n",
    "                    images.append(img_array)\n",
    "                    labels.append(class_folder)  # Use folder name as label\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {str(e)}\")\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "    \n",
    "data = load_images_from_folder(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e87584-4672-40dc-8c11-5df98a21af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle_data(data):\n",
    "    images, labels = data\n",
    "    \n",
    "    indices = np.random.permutation(len(images))\n",
    "    images = images[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def classify_labels(labels):\n",
    "    new_labels = []\n",
    "    # Initialize an empty dictionary\n",
    "    object_dict = {}\n",
    "    \n",
    "    # Open the file and read its contents\n",
    "    with open(\"map_id_label.txt\", \"r\") as file:\n",
    "        # Iterate over each line in the file\n",
    "        for line in file:\n",
    "            # Split the line based on the comma delimiter\n",
    "            parts = line.strip().split(\",\")\n",
    "            # Extract the key and value from the split parts\n",
    "            value = int(parts[0])  # Convert the key to integer\n",
    "            key = parts[1]\n",
    "            # Add the key-value pair to the dictionary\n",
    "            object_dict[key] = int(value)\n",
    "\n",
    "    for i, c in enumerate(labels):\n",
    "        if c in object_dict:\n",
    "            new_labels.append(object_dict[c])\n",
    "    \n",
    "    return np.array(new_labels)\n",
    "\n",
    "images, labels = data #shuffle_data(data)\n",
    "labels = classify_labels(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483103b5-5a3e-4969-8613-4601f5117c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.20, train_size=0.80, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b549097-d5a9-4989-b188-45cedece5bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(1111, 1111, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, \n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9bd45b-6101-46c4-8f65-303bec61e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a71c0-2552-40d4-a247-a3a208c9a8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
